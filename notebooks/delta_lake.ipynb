{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a93c16",
   "metadata": {},
   "source": [
    "# Delta Lake - Cidades Brasileiras\n",
    "\n",
    "Este notebook demonstra a criação, leitura e manipulação de uma tabela Delta usando o dataset `cidades_brasileiras.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = SparkSession.builder     .appName(\"Delta Lake - Cidades\")     .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")     .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"cidade\", StringType(), True),\n",
    "    StructField(\"estado\", StringType(), True),\n",
    "    StructField(\"sigla\", StringType(), True),\n",
    "    StructField(\"ibge\", IntegerType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"../data/cidades_brasileiras.csv\", header=True, schema=schema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"../output/delta/cidades\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cidades_delta\")\n",
    "spark.sql(\"CREATE TABLE cidades_delta USING DELTA LOCATION '../output/delta/cidades'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "nova_cidade = [Row(id=9999, cidade=\"Nova Esperança\", estado=\"Paraná\", sigla=\"PR\", ibge=9999999, latitude=-23.5, longitude=-51.5)]\n",
    "nova_df = spark.createDataFrame(nova_cidade)\n",
    "nova_df.write.format(\"delta\").mode(\"append\").save(\"../output/delta/cidades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05352d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"UPDATE cidades_delta SET cidade = 'Cidade Atualizada' WHERE id = 9999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DELETE FROM cidades_delta WHERE id = 9999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e004931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = spark.read.format(\"delta\").load(\"../output/delta/cidades\")\n",
    "df_final.show(5)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}